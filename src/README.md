# Weblate-Translation-Project-Crawler-Tool
# Weblate 翻译项目爬虫工具
鉴于之前写的那个代码实在是太差劲了，我觉得有必要重新按照相关标准重写一份，引入更为先进的包，使用更为安全的异常处理机制，同时遵循更加规范的书写格式。

按照需求，整个工具分为三部分
1. 爬虫部分：能够爬取特定模组和整合包。
2. 分析部分：需要拆模组得到语言文件，需要拆整合包得到里面的`json`文件，然后检索未下载模组进行下载。
3. 处理部分：拆包得到 `en_us.lang`、`zh_cn.lang` 要与 weblate 已翻译文件进行对比更新，同时 `zh_cn.lang` 文件需要得到保留，作为发布时候剔除冗余的参考。
4. 剔除冗余部分：最后发布时候的脚本，用来对比 weblate 翻译文件和原 mod 文件中中文文件，剔除重复部分，只保留翻译部分。打包成 Minecraft 官方的标准资源包格式。

## 1. 爬虫部分计划需求
- 脚本应当提供一个配置文件（YAML格式），能够设定爬虫爬取的页数、黑名单、白名单。
- 爬虫应当是多线程的，提升爬取速度。但是速度不易过快，防止被 curse 官方封锁。
- 爬虫应当是增量更新，即二次爬取的时候，能够读取上次的记录，只对更新的部分进行爬取。
- 爬虫要按照 mod 区的页数、爬取特定版本、按照下载量排名的模组，还要能爬取特定版本、按照下载量排名的整合包区的整合包。
- 爬虫应当要爬取 [https://minecraft.curseforge.com](https://minecraft.curseforge.com) 的文件，而不是 [https://www.curseforge.com](https://www.curseforge.com) 的文件，因为第二个网址不提供 alpha 版本模组下载。
- 爬虫需要提供全面的异常处理机制，比如`5xx`错误重试，`4xx`错误跳过功能。
- 爬虫能够爬取白名单上面的模组，而不爬取黑名单模组。

## 2. 分析部分计划需求
- 需要拆包得到 `en_us.lang` 和 `zh_cn.lang`，但是鉴于 1.12 目前大小写语言文件名情况层出不穷，统一将其处理为小写。
- 需要拆整合文件，得到里面的 `manifest.json` 文件，进行检索下载。

## 3. 处理部分计划需求
- 首先将拆包得到的 `en_us.lang` 和 `zh_cn.lang` 进行混编。而后将 Weblate 上的翻译文件与混编文件进行对比更新，只保留中文部分。
- 上一步拆包得到 `en_us.lang` 需要直接覆盖仓库中旧的 `en_us.lang`。而上一步拆包得到 `zh_cn.lang` 则需要变为 `zh_cn_old.lang` 保留，留作发布时候剔除冗余的参考文件。

## 4. 剔除部分计划需求
- 能够识别翻译过的文件和  `zh_cn_old.lang` 中相同的部分，剔除重复部分。
- 最后按照 Minecraft 资源文件标准格式进行打包。
